<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pruning | Simone Magnani</title><link>https://s41m0n.github.io/category/pruning/</link><atom:link href="https://s41m0n.github.io/category/pruning/index.xml" rel="self" type="application/rss+xml"/><description>pruning</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Copyright `2024` Simone Magnani</copyright><lastBuildDate>Sun, 17 Dec 2023 10:00:00 +0200</lastBuildDate><image><url>https://s41m0n.github.io/media/me.png</url><title>pruning</title><link>https://s41m0n.github.io/category/pruning/</link></image><item><title>Pruning Federated Learning Models for Anomaly Detection in Resource-Constrained Environments</title><link>https://s41m0n.github.io/talk/bigdata23/</link><pubDate>Sun, 17 Dec 2023 10:00:00 +0200</pubDate><guid>https://s41m0n.github.io/talk/bigdata23/</guid><description>&lt;p>The evolving complexity of modern IT infrastructures has paved the way for malicious actors to exploit a wide array of vulnerabilities that can compromise the integrity of these systems. Monitoring complex IT systems is expensive and often requires dedicated infrastructure for deploying Intrusion and/or Anomaly Detection Systems. Moreover, ML-based solutions need large training sets, which add to the overall cost. To tackle these challenges we present INTELLECT, a novel approach to Intrusion and/or Anomaly Detection System, which leverages Federated Learning and model pruning techniques to cooperatively train high-accuracy models using distributed datasets and derive a fleet of lightweight models, which can be deployed without incurring additional costs for dedicated infrastructure. INTELLECT expands on the state-of-the-art techniques for feature selection, model pruning, and model distillation to create an interconnected pipeline. We empirically demonstrate the effectiveness of the methodology on benchmark datasets, and we present guidelines for the deployment in production systems.&lt;/p>
&lt;p>This research has been carried on in collaboration with IBM Research Centre, Ireland.&lt;/p></description></item><item><title>Enhancing Network Intrusion Detection: An Online Metodology for Performance Evaluation</title><link>https://s41m0n.github.io/talk/netsoft23/</link><pubDate>Sun, 16 Jul 2023 10:00:00 +0200</pubDate><guid>https://s41m0n.github.io/talk/netsoft23/</guid><description>&lt;p>Machine learning models have been extensively proposed for classifying network flows as benign or malicious, either in-network or at the endpoints of the infrastructure. Typically, the performance of such models is assessed by evaluating the trained model against a portion of the available dataset. However, in a production scenario, these models are fed by a monitoring stage that collects information from flows and provides inputs to a filtering stage that eventually blocks malicious traffic. To the best of our knowledge, no work has analysed the entire pipeline, focusing on its performance in terms of both inputs (i.e., the information collected from each flow) and outputs (i.e., the system’s ability to prevent an attack from reaching the application layer).In this paper, we propose a methodology for evaluating the effectiveness of a Network Intrusion Detection System (NIDS) by placing the model evaluation test alongside an online test that simulates the entire monitoring-detection-mitigation pipeline. We assess the system’s outputs based on different input configurations, using state-of-the-art detection models and datasets. Our results highlight the importance of inputs for the throughput of the NIDS, which can decrease by more than 50% with heavier configurations. Furthermore, our research indicates that relying solely on the performance of the detection model may not be enough to evaluate the effectiveness of the entire NIDS process. Indeed, even when achieving near-optimal False Negative Rate (FNR) values (e.g., 0.01), a substantial amount of malicious traffic (e.g., 70%) may still successfully reach its target.&lt;/p></description></item></channel></rss>